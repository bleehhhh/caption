<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BLIP Image Captioner</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e0e0e0;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        #upload-container {
            width: 90%;
            max-width: 900px;
            background: rgba(30, 30, 46, 0.95);
            border: 3px dashed #ff6b35;
            border-radius: 15px;
            padding: 40px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            backdrop-filter: blur(10px);
        }

        h1 {
            text-align: center;
            color: #ff6b35;
            margin-bottom: 10px;
            font-size: 2em;
        }

        .subtitle {
            text-align: center;
            color: #888;
            margin-bottom: 30px;
            font-size: 0.9em;
        }

        #model-name-input {
            width: 100%;
            padding: 15px;
            margin-bottom: 25px;
            background: rgba(255, 255, 255, 0.05);
            border: 2px solid rgba(255, 107, 53, 0.3);
            border-radius: 8px;
            color: #e0e0e0;
            font-size: 16px;
            transition: all 0.3s;
        }

        #model-name-input:focus {
            outline: none;
            border-color: #ff6b35;
            background: rgba(255, 255, 255, 0.08);
        }

        #model-name-input::placeholder {
            color: #666;
        }

        #drop-zone {
            border: 2px dashed rgba(255, 107, 53, 0.5);
            border-radius: 12px;
            padding: 50px 20px;
            text-align: center;
            cursor: pointer;
            transition: all 0.3s;
            background: rgba(255, 255, 255, 0.02);
            margin-bottom: 25px;
            min-height: 200px;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
        }

        #drop-zone:hover, #drop-zone.dragover {
            background: rgba(255, 107, 53, 0.1);
            border-color: #ff6b35;
            transform: translateY(-2px);
        }

        #drop-zone.has-files {
            min-height: auto;
            padding: 20px;
        }

        .drop-text {
            font-size: 1.2em;
            color: #888;
            margin-bottom: 10px;
        }

        .drop-icon {
            font-size: 3em;
            color: #ff6b35;
            margin-bottom: 15px;
        }

        #file-input {
            display: none;
        }

        #preview-box {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }

        .preview-item {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 10px;
            padding: 10px;
            transition: transform 0.3s;
            position: relative;
        }

        .preview-item:hover {
            transform: translateY(-5px);
            background: rgba(255, 255, 255, 0.08);
        }

        .preview-item img {
            width: 100%;
            height: 150px;
            object-fit: cover;
            border-radius: 8px;
            margin-bottom: 8px;
        }

        .preview-item .filename {
            font-size: 12px;
            color: #aaa;
            text-align: center;
            word-break: break-word;
        }

        .preview-item .number {
            position: absolute;
            top: 15px;
            left: 15px;
            background: #ff6b35;
            color: white;
            width: 25px;
            height: 25px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 12px;
            font-weight: bold;
        }

        #process-button {
            width: 100%;
            background: linear-gradient(135deg, #ff6b35 0%, #f7931e 100%);
            color: white;
            padding: 18px;
            font-size: 18px;
            font-weight: bold;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s;
            margin-top: 20px;
        }

        #process-button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 5px 20px rgba(255, 107, 53, 0.4);
        }

        #process-button:disabled {
            background: #555;
            cursor: not-allowed;
            opacity: 0.6;
        }

        #status {
            margin-top: 20px;
            padding: 15px;
            border-radius: 8px;
            text-align: center;
            display: none;
        }

        #status.info {
            background: rgba(33, 150, 243, 0.2);
            border: 1px solid #2196F3;
            color: #64B5F6;
            display: block;
        }

        #status.success {
            background: rgba(76, 175, 80, 0.2);
            border: 1px solid #4CAF50;
            color: #81C784;
            display: block;
        }

        #status.error {
            background: rgba(244, 67, 54, 0.2);
            border: 1px solid #f44336;
            color: #E57373;
            display: block;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            overflow: hidden;
            margin-top: 15px;
            display: none;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #ff6b35, #f7931e);
            width: 0%;
            transition: width 0.3s;
        }
    </style>
</head>
<body>
    <div id="upload-container">
        <h1>üñºÔ∏è BLIP Image Captioner</h1>
        <p class="subtitle">Upload images and generate captions for LoRA training</p>
        
        <input type="text" id="model-name-input" placeholder="Enter model/character name (e.g., 'john_doe')">
        
        <div id="drop-zone">
            <div class="drop-icon">üìÅ</div>
            <div class="drop-text">Click to upload or drag & drop images</div>
            <small style="color: #666;">Supports JPG, PNG, WEBP</small>
        </div>

        <input type="file" id="file-input" multiple accept="image/*">
        
        <div id="preview-box"></div>
        
        <button id="process-button">Generate Captions & Download</button>
        
        <div id="status"></div>
        <div class="progress-bar">
            <div class="progress-fill"></div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
    <script type="module">
        import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';

        // Configure to use local models if available, otherwise use CDN
        env.allowLocalModels = false;

        const dropZone = document.getElementById('drop-zone');
        const fileInput = document.getElementById('file-input');
        const previewBox = document.getElementById('preview-box');
        const processButton = document.getElementById('process-button');
        const modelNameInput = document.getElementById('model-name-input');
        const statusDiv = document.getElementById('status');
        const progressBar = document.querySelector('.progress-bar');
        const progressFill = document.querySelector('.progress-fill');
        
        let selectedFiles = [];
        let captioner = null;

        // Initialize the model
        async function initModel() {
            if (!captioner) {
                showStatus('Loading Vision model (first time may take a minute)...', 'info');
                try {
                    // Using ViT-GPT2 which is supported by Transformers.js
                    captioner = await pipeline('image-to-text', 'Xenova/vit-gpt2-image-captioning');
                    showStatus('Model loaded successfully!', 'success');
                    setTimeout(() => statusDiv.style.display = 'none', 2000);
                } catch (error) {
                    showStatus('Error loading model: ' + error.message, 'error');
                    console.error(error);
                }
            }
        }

        // Start loading model immediately
        initModel();

        // Click to upload
        dropZone.addEventListener('click', () => fileInput.click());

        // Drag and drop handlers
        ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
            dropZone.addEventListener(eventName, preventDefaults, false);
        });

        function preventDefaults(e) {
            e.preventDefault();
            e.stopPropagation();
        }

        ['dragenter', 'dragover'].forEach(eventName => {
            dropZone.addEventListener(eventName, () => dropZone.classList.add('dragover'), false);
        });

        ['dragleave', 'drop'].forEach(eventName => {
            dropZone.addEventListener(eventName, () => dropZone.classList.remove('dragover'), false);
        });

        dropZone.addEventListener('drop', handleDrop);
        fileInput.addEventListener('change', (e) => handleFiles(e.target.files));

        function handleDrop(e) {
            const files = e.dataTransfer.files;
            handleFiles(files);
        }

        function handleFiles(files) {
            const imageFiles = Array.from(files).filter(file => file.type.startsWith('image/'));
            
            if (imageFiles.length === 0) {
                showStatus('Please select valid image files', 'error');
                return;
            }

            selectedFiles = imageFiles;
            displayPreviews();
            dropZone.classList.add('has-files');
            dropZone.innerHTML = `<div class="drop-text">‚úì ${imageFiles.length} image(s) selected</div>`;
        }

        function displayPreviews() {
            previewBox.innerHTML = '';
            
            selectedFiles.forEach((file, index) => {
                const reader = new FileReader();
                reader.onload = (e) => {
                    const previewItem = document.createElement('div');
                    previewItem.className = 'preview-item';
                    previewItem.innerHTML = `
                        <div class="number">${index + 1}</div>
                        <img src="${e.target.result}" alt="${file.name}">
                        <div class="filename">${index + 1}.${file.name.split('.').pop()}</div>
                    `;
                    previewBox.appendChild(previewItem);
                };
                reader.readAsDataURL(file);
            });
        }

        // Process and caption images
        processButton.addEventListener('click', async () => {
            if (selectedFiles.length === 0) {
                showStatus('Please upload some images first', 'error');
                return;
            }

            const modelName = modelNameInput.value.trim();
            if (!modelName) {
                showStatus('Please enter a model name', 'error');
                return;
            }

            // Make sure model is loaded
            await initModel();
            if (!captioner) {
                showStatus('Model not loaded. Please try again.', 'error');
                return;
            }

            processButton.disabled = true;
            progressBar.style.display = 'block';
            showStatus('Processing images...', 'info');

            try {
                const zip = new JSZip();
                
                for (let i = 0; i < selectedFiles.length; i++) {
                    const file = selectedFiles[i];
                    const fileExt = file.name.split('.').pop();
                    const newFilename = `${i + 1}.${fileExt}`;
                    
                    // Update progress
                    const progress = ((i + 1) / selectedFiles.length) * 100;
                    progressFill.style.width = progress + '%';
                    showStatus(`Processing ${i + 1}/${selectedFiles.length}: ${file.name}`, 'info');
                    
                    // Add image to zip
                    zip.file(newFilename, file);
                    
                    // Generate caption using BLIP
                    const caption = await generateCaption(file, modelName);
                    
                    // Add caption text file
                    zip.file(`${i + 1}.txt`, caption);
                }

                // Generate and download zip
                showStatus('Creating zip file...', 'info');
                const content = await zip.generateAsync({type: 'blob'});
                const url = URL.createObjectURL(content);
                const a = document.createElement('a');
                a.href = url;
                a.download = `${modelName}_training_dataset.zip`;
                a.click();
                URL.revokeObjectURL(url);

                showStatus('‚úì Success! Dataset downloaded', 'success');
                progressFill.style.width = '100%';
                
            } catch (error) {
                showStatus('Error: ' + error.message, 'error');
                console.error(error);
            } finally {
                processButton.disabled = false;
                setTimeout(() => {
                    progressBar.style.display = 'none';
                    progressFill.style.width = '0%';
                }, 2000);
            }
        });

        // Generate caption using BLIP model
        async function generateCaption(imageFile, modelName) {
            try {
                // Create image URL for the model
                const imageUrl = URL.createObjectURL(imageFile);
                
                // Generate caption using BLIP
                const result = await captioner(imageUrl, {
                    max_new_tokens: 50,
                });
                
                // Clean up the URL
                URL.revokeObjectURL(imageUrl);
                
                // Get the generated text
                const generatedCaption = result[0].generated_text;
                
                // Format the caption with the model name
                // BLIP provides a base caption, we enhance it with the model token
                const finalCaption = `A photo of ${modelName}, ${generatedCaption}`;
                
                return finalCaption;
                
            } catch (error) {
                console.error('Error generating caption:', error);
                return `A photo of ${modelName}`;
            }
        }

        function showStatus(message, type) {
            statusDiv.textContent = message;
            statusDiv.className = type;
        }
    </script>
</body>
</html>
